% !TeX root = main.tex

\section{EXPERIMENTS}
\label{sec: experiments}


\begin{frame}{}
    \begin{itemize}
        \item まず, \hlink{theorem1}{Theorem 1}  \hlink{theorem2}{Theorem 2} の方法を合成ワークロードとケーススタディの両方で実験を行うことによって評価する
        \item 次に, マルチスレッドエグゼキュータとシングルスレッドエグゼキュータのリアルタイムパフォーマンスを比較する
        \item 特に, マルチスレッドのエグゼキュータによってスケジュールされたチェーンの応答時間は, シングルスレッドのエグゼキュータよりもさらに悪い可能性があることを示す
    \end{itemize}
\end{frame}


\subsection{Synthetic workload}
\label{ssec: synthetic workload}

\begin{frame}{システム $\Gamma$ の生成方法1}
    \begin{itemize}
        \item チェーン $|\Gamma|$ の数は $[2, n]$ の範囲でランダムに選択され, 各チェーン $\mathcal{C}_{i}$ のコールバック $\left|\mathcal{C}_{i}\right|$ の数は $[2, b]$ の範囲でランダムに選択される
              \begin{itemize}
                  \item $n$ と $b$ はパラメータである
              \end{itemize}
        \item $\mathcal{C}_{i}$ の期間 $T_{i}$ は [50,200] の範囲でランダムに選択され, 相対デッドライン $D_{i}$ は $T_{i}$ に等しくなるように設定される
    \end{itemize}
\end{frame}

\begin{frame}{システム $\Gamma$ の生成方法2}
    \begin{itemize}
        \item 各チェーンの利用率 $U_{i}$ は, UUniFast法*によって生成される
        \item 全てのチェーンの合計利用率は, 正規化された利用率 $U_{n o r m}$ に $m$ を掛けて決定される $(0, m]$ の範囲で選択され, システムの総利用率を各チェーンに分配する
              \begin{itemize}
                  \item 各 $\mathcal{C}_{i}$ の $U_{i}$ は 1 以下にする
              \end{itemize}
        \item 同様の方法で, 各チェーンの利用率を個々のコールバックに分配し, 各コールバックの WCET は, その利用率に周期 $T_{i}$を掛けることによって導き出される (最も近い整数に丸められる)
    \end{itemize}
    \source{*P.Emberson et al., “Techniques for the synthesis of multiprocessor tasksets,” pp. 6–11, 2010.}
\end{frame}

\begin{frame}{システム $\Gamma$ の生成方法3}
    \begin{itemize}
        \item mutually exclusiveグループの数 $\left|\bigcup_{\forall \mathcal{C}_{i} \in \Gamma} \theta_{i}\right|$ は, $g$ をパラメーターとして $[0, g]$ の範囲内でランダムに選択される
        \item mutually exclusiveグループ内のコールバックの総数は, $\alpha$ が $[0.1,1]$ に収まる比率である $\alpha \sum_{i=1}^{|\Gamma|}\left|\mathcal{C}_{i}\right|$ によって決定される
        \item mutually exclusive コールバックグループのコールバックは, 全てのコールバックからランダムに選択され, 各コールバックグループに分配される
        \item 残りのコールバックは全てreentrantコールバックグループに割り当てられる
    \end{itemize}
\end{frame}

\begin{frame}{システム $\Gamma$ の生成方法4}
    \begin{itemize}
        \item 各コールバックの優先度は, $\left\{1,2, \cdots, \sum_{i=1}^{|\Gamma|}\left|\mathcal{C}_{i}\right|\right\}$ からランダムに選択された一意の ID に従う
        \item 数値が小さいほど, 優先度が高くなる
        \item 各構成 (各図の $\mathrm{x}$ 軸上の 1 点) に対して, 500 のタスクシステムを生成する
    \end{itemize}
\end{frame}

\begin{frame}{パフォーマンス比較方法}
    \begin{itemize}
        \item  \al{OUR-1}: \hlink{theorem3}{Theorem 3}  \hlink{theorem1}{Theorem 1} によって実行されるスケジュール可能性テスト

        \item  \al{OUR-2}: \hlink{theorem3}{Theorem 3}  \hlink{theorem2}{Theorem 2} によって実行されるスケジュール可能性テスト

        \item  \al{SIMU}: 全てのチェーンが最初のインスタンスを同時にリリースし, 各チェーンができるだけ早くインスタンスをリリースし, 各コールバックインスタンスが WCET で実行されると仮定した場合の, シミュレーションでの各チェーンの観測された最大応答時間
              \begin{itemize}
                  \item シミュレーションは 5000 時間単位続く
                  \item 結果は, 実際の最悪の場合の応答時間の測定された下限に基づいている
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{実験方法}
    本セクションの実験では, 以下の基本設定をして, 実験の各グループで 1 つのパラメーターを変更し, 他のパラメーターは変更しない
    \begin{itemize}
        \item $m=4$
        \item $n=8$
        \item $b=5$
        \item $U_{n o r m}=0.3$
        \item $g=2$
        \item $\alpha=0.2$
    \end{itemize}
\end{frame}

\begin{frame}{評価指標}
    \begin{itemize}
        \item パフォーマンスは\al{受入率}で評価する
        \item 受入率: スケジュール可能なタスクシステムの数とタスクシステム全体の数の比率
        \item 各図の $y$ 軸は受入率を示す
    \end{itemize}
\end{frame}

\begin{frame}{異なる $U_{\text {norm }}$ における受入率}
    \fullimage{exp_random_u.png}
\end{frame}

\begin{frame}{異なる $n$ における受入率}
    \fullimage{exp_random_n.png}
\end{frame}

\begin{frame}{異なる $b$ における受入率}
    \fullimage{exp_random_b.png}
\end{frame}

\begin{frame}{異なる $g$ における受入率}
    \fullimage{exp_random_n.png}
\end{frame}

\begin{frame}{異なる $\alpha$ における受入率}
    \fullimage{exp_random_alpha.png}
\end{frame}

\begin{frame}{異なるスレッド数 $m$ における受入率}
    \fullimage{exp_random_m.png}
\end{frame}

\begin{frame}{結果の考察}
    \begin{itemize}
        \item OUR-2 はさまざまなパラメーター設定の下で一貫して OUR-1 よりも優れており, 比較的大きなギャップがある
        \item 特に, OUR-2 の結果は SIMU よりも低く, この方法が安全であることを示す
        \item しかし, SIMU と OUR-2 の間にはまだ余裕がある
        \item その理由の 1 つは, SIMU が比較的短い時間間隔で測定されるため, 安全な境界ではなないため (シミュレーションには非常に時間がかかり, 妥当なサンプルサイズを維持しながらシミュレーションを長時間実行することはできない)
    \end{itemize}
\end{frame}

\begin{frame}{提案手法の改善余地}
    \begin{itemize}
        \item 単純な改善は, 各干渉チェーン $\mathcal{C}_{k}$ のより正確な $\overrightarrow{\mathcal{M}}_{k}$ を取得するために「キャリーイン」と「キャリーアウト」のコールバックインスタンスの全ての組み合わせを考慮することである (本論文では, これは最大数のチェーンインスタンス全体を含むと想定されている)
        \item この改善はより厳密な応答時間の境界を取得する (スペースの制限のため, ここではアルゴリズムを提示しない)
        \item また, より正確なテストを導出するために, より多くの制約を作成することもできる
        \item これは, 本論文の方法で簡単に拡張できる
    \end{itemize}
\end{frame}


\subsection{Case studies}
\label{ssec: case studies}

\begin{frame}{}
    \begin{itemize}
        \item ケーススタディを使用して分析手法を評価する
        \item また, シングルスレッドエグゼキュータとマルチスレッドエグゼキュータでのパフォーマンスの違いを実証するための経験的評価を示す
    \end{itemize}
\end{frame}

\begin{frame}{実行環境}
    カーネル 5.4.0-113-generic を搭載した Ubuntu 20.04.4 LTS と Intel i5-7500 CPU を搭載した PC で実行される ROS 2 Foxy Fitzroy に展開される
    \notes{マルチスレッドエグゼキュータを提供するために 2 つのコアが使用される}
\end{frame}


\begin{frame}{ケーススタディの概要}
    \fitimage{
        \begin{itemize}
            \item ケーススタディの簡単な説明を表に示す
            \item これらは Choiら*が現実的な自律走行システムから開発したサブチェーンを引用
        \end{itemize}
    }{exp_case_study_desc.png}
    \source{*H.Choi et al., “PiCas: New design of prioritydriven chain-aware scheduling for ros2,” in RTAS, 2021.}
\end{frame}

\begin{frame}{実験方法}
    \begin{itemize}
        \item 2スレッドのマルチスレッド実行系とシングルスレッド実行系でそれぞれ5分間実行し, 各チェーンの平均ケース応答時間（ACRT）と最悪ケース応答時間（WCRT）を測定する（これは安全境界ではない）
        \item \hlink{theorem2}{Theorem 2} により各鎖の応答時間境界を計算し, 観測された下限と比較する
    \end{itemize}
\end{frame}


\begin{frame}{ケーススタディ1による実験結果}
    \fitimage{
        \begin{itemize}
            \item 全てのコールバックがリエントラントコールバックグループに属すとして, ケーススタディ1による実験結果を表に示す
            \item マルチスレッド実行系でスケジューリングされた各チェインの応答時間はシングルスレッド実行系よりはるかに小さいことがわかる
            \item さらに, 我々の方法は安全であり, 測定された下限値に近い
        \end{itemize}
    }{exp_case_study_1.png}
\end{frame}

\begin{frame}{ケーススタディ2による実験で示すこと}
    \begin{itemize}
        \item 本論文が観察した興味深い問題は, マルチスレッドのエグゼキュータによってスケジュールされたチェーンの応答時間が, シングルスレッドのエグゼキュータよりもはるかに遅くなる可能性があること
        \item 特に, 全てのコールバックがmutually exclusive同じグループにある場合でも, 全てのコールバックが強制的に順次実行されるマルチスレッドエグゼキュータでのスケジューリングは, シングルスレッドエグゼキュータでのスケジューリングとは大きく異なる
    \end{itemize}
\end{frame}

\begin{frame}{ケーススタディ2による実験結果}
    \fitimage{
        全てのコールバックが 同じmutually exclusiveグループに属すとして, 結果を表に示す
    }{exp_case_study_2.png}
\end{frame}

\begin{frame}{観測された問題}
    \fitimage{
        マルチスレッドスケジューラにおける $\mathcal{C}_3$ の応答時間は, シングルスレッドエグゼキュータでの応答時間よりもはるかに長い
    }{exp_case_study_2_sup.png}
\end{frame}

\begin{frame}{観測された問題の原因考察1}
 \begin{itemize}
    \item マルチスレッドエグゼキュータの下でコールバックインスタンスがブロックされ, wait\_set から削除される可能性があることが原因と考えられる
    \item あるコールバックインスタンスを考えた場合, それより優先度の高い ready コールバックインスタンスと一緒に wait\_set に追加される可能性がある
    \item このとき, 優先度の高いコールバックインスタンスが最初にスケジュールされるため, このコールバックインスタンスはブロックされ, wait\_set から削除される
    \item この状況が数回繰り返され, このコールバックインスタンスが何度もブロックされる可能性がある
 \end{itemize}
\end{frame}

\begin{frame}{観測された問題の原因考察2}
    対照的に, シングルスレッドエグゼキュータでは, コールバックインスタンスは wait\_set から削除されないため, 同時に wait\_set に追加されていないコールバックインスタンスによってブロックされない
\end{frame}

\begin{frame}{観測された問題の例}
    \fitimage{
        \begin{itemize}
            \item トレースツール ROS2\_tracing で生成したケーススタディ2の結果のシーケンスの一部を図に示す
            \item 各チェーンのチェーンインスタンスは, 赤い矢印でマークされた時点で同時にリリースされる
        \end{itemize}
    }{exp_problem_ex.png}
\end{frame}

\begin{frame}{観測された問題の例補足}
    \fullimage{exp_problem_ex_sup.jpg}
\end{frame}

\begin{frame}{観測された問題からの示唆}
    マルチスレッドエグゼキュータ上にシステムを実装するとき, または複数のシングルスレッドエグゼキュータからのコールバックをマルチスレッドエグゼキュータにマージするときに, コールバックのコールバックグループの割り当てを慎重に検討する必要がある
\end{frame}
